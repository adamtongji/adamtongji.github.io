---
layout: post
title: 机器学习问答
categories: [机器学习, 算法, 费曼]
description: 机器学习课程解决细节疑难
keywords: 机器学习, 复习
---

1. 机器学习模型有哪些？<br>
有监督线性分类器，包括KNN，线性分类(LDA)，广义线性分类（Logistic)等。  <br>
有监督线性回归，包括线性回归，LASSO/ridge回归等。 <br>
有监督非线性分类器，包括SVM，随机森林（决策树）和神经网络等等。<br>
无监督分类器，包括PCA，Kmeans等等。<br>

2. 回归同分类目标函数的区别是什么？<br>
回归计算的是预测同实际值最小二乘法的误差。而分类计算的是分类后总体的交叉信息熵。

3. SVM的模型及目标函数，优化方法和正则化方法分别是什么？<br>
将所有点升至N维度，通过最小二乘法计算误差值，其中去掉到超平面距离小于松弛变量的点，找到最优超平面。**如何得到超平面的公式需要再复习**<br>
优化方法是核函数，原函数d维，共m个点，最高需要m+d维分开，而通过高斯核或者线性核，可以隐性映射到较低维空间。<br>
正则化还未了解。<br>

4. 决策树的模型，目标函数，优化方法和正则化方法分别是什么？<br>
决策树是通过选取的多个特征，进行多次二分类后，将样本分类至尽可能纯的子叶节点下。<br>
决策树的目标函数就是分类和子节点的交叉熵最小。<br>
优化方法有bagging（随机采样,多分类和回归）,boosting（Adaboost，gbdt,对表现好的节点给予更高权重，二分类)和随机森林（对样本和feature都进行随机采样）。以及ensembl(这几个的融合方法)。<br>
决策树的正则化通过交叉熵，以及分类复杂度的幂函数（控制树的大小和节点数目）来避免过拟合。对于叶节点，也会采用dropout的方法正则化。<br>






